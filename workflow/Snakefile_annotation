#########################################
#   workflow for the Sacculina Genome   #
#       annotation and orthology        #
#########################################

# report: "report/workflow.rst"

localrules: funannotate_setup
configfile: "workflow/config/config.yaml"

import pandas as pd 
from os import listdir
from os.path import isfile, join

samples = pd.read_table(config["sample_info"] , dtype=str).set_index(["Sample"], drop=False)
samples_cirri = pd.read_table(config["sample_info_cirri"] , dtype=str).set_index(["Sample"], drop=False)
externals = pd.read_table(config["sample_external"] , dtype=str).set_index(["species"], drop=False)

CIRRI_SPEC=['Tetraclita_japonica_formosana', 'Amphibalanus_amphitrite', 'Pollicipes_pollicipes']

## Functions 

def get_sample_forward_cirri(sample_id):         
    dct = {}
    for i, j in zip(samples_cirri['Sample'],samples_cirri['Forward']):
        dct.setdefault(i, []).append( j)
    forward = dct[sample_id]
    return forward 

def get_sample_reverse_cirri(sample_id):
    dct = {}
    for i, j in zip(samples_cirri['Sample'],samples_cirri['Reverse']):
        dct.setdefault(i, []).append( j)
    reverse = dct[sample_id]
    return reverse

def get_taxon_cirri(sample_id):
    area_dict = dict(zip(samples_cirri['Sample'],samples_cirri['Taxon']))
    taxon = area_dict[sample_id]
    return taxon

def get_tsa_file(wildcards):
    area_dict = dict(zip(externals['species'],externals['file'])) 
    file = area_dict[wildcards.species] 
    return file

def get_all_tsa_files():
    mylist = []
    for file in  externals['file'].tolist():
        mylist.append(file)
    return set(mylist)

def get_sample_forward(sample_id):     
    area_dict = dict(zip(samples['Sample'],samples['Forward']))
    forward = area_dict[sample_id]     
    return forward

def get_sample_reverse(sample_id):
    area_dict = dict(zip(samples['Sample'],samples['Reverse']))
    reverse = area_dict[sample_id]
    return reverse

def print_all_forward():
    mylist=[]
    for dataset in samples['Sample'].tolist():
        mylist.append("results/trim/{sample}_1.fq.gz".format(sample=dataset))
    return sorted(set(mylist))

def print_all_reverse():
    mylist=[]
    for dataset in samples['Sample'].tolist():
        mylist.append("results/trim/{sample}_2.fq.gz".format(sample=dataset))     
    return sorted(set(mylist))

## WORKFLOW ##

rule all:
    input:
        dynamic("results/orthofinder/interproscan/{orthogroup}.tsv"),
        "results/funannotate2/annotate_step.complete"
    shell:
         """
	 echo "final step"	
         """

rule repeat_modeler:
    input:
        genome="resources/saca8_scp1p2_v0.2.fasta"
    output:
        "results/annotation/repeats/MyDatabase-families.fa"
    params:
        database="MyDatabase",
        work="results/annotation/repeats",
        engine="ncbi"
    threads: 50
    container: 
        config["masking"]["container"]
    shell:
        """
        [ ! -d {params.work} ] && mkdir -p {params.work} # create working directory
        cp {input.genome} {params.work}/Genome.fasta
        cd {params.work}
        BuildDatabase -engine {params.engine} -name {params.database} Genome.fasta

        RepeatModeler -database {params.database} -engine {params.engine} -pa {threads}

        """

### remove proteome hits from repeat database

rule repeat_masker:
    input:
        "results/annotation/repeats/MyDatabase-families.fa"
    output:
        "results/annotation/repeats/Genome.fasta.masked"
    params:
        database="MyDatabase",
        work="results/annotation/repeats",
        engine="ncbi"
    threads: 50
    container: 
        config["masking"]["container"]
    shell:
        """
        [ ! -d {params.work} ] && mkdir -p {params.work} # create working directory
        cd {params.work}
        RepeatMasker Genome.fasta -lib ../../../{input} -pa {threads}
        
        calcDivergenceFromAlign.pl -s Assembly_div_summary Genome.fasta.cat.gz
        createRepeatLandscape.pl -div Assembly_div_summary -g 365000000 > Genome_repeatlandscape.html

        """

## prepare Sacculina RNA-Seq data
rule rename_reads:
    output:
        R1=temp("results/raw/{sample}_1.fq.gz"),
        R2=temp("results/raw/{sample}_2.fq.gz")
    params:
        fwd=lambda wildcards: get_sample_forward('{sample_id}'.format(sample_id=wildcards.sample) ),
        rev=lambda wildcards: get_sample_reverse('{sample_id}'.format(sample_id=wildcards.sample) )
    shell:
        """
cat resources/RNA-Seq/{params.fwd} > {output.R1}
cat resources/RNA-Seq/{params.rev} > {output.R2}

        """


rule Trim_raw2:
    input:
        R1="results/raw/{sample}_1.fq.gz",
        R2="results/raw/{sample}_2.fq.gz"
    output: 
        R1="results/trim/{sample}_1.fq.gz",
        R2="results/trim/{sample}_2.fq.gz"
    log: 
        "results/logs/{sample}_fastp.log"
    threads:
        8
    shell: 
        """
(fastp -i {input.R1} -I {input.R2} -o {output.R1} -O {output.R2} --length_required 100 --thread {threads} --low_complexity_filter --detect_adapter_for_pe --trim_poly_x \
 --json results/logs/fastp/{wildcards.sample}.fastp.json \
 --html results/logs/fastp/{wildcards.sample}.fastp.html ) &> {log}
        """
 

######################################
## assemble external transcriptomes ##
######################################

# resources/Cirripedia_trans/

rule rename_reads_external:
    output:         
        R1=temp("results/cirri_raw/{sample}_1.fq.gz"),
        R2=temp("results/cirri_raw/{sample}_2.fq.gz")
    params: 
        fwd=lambda wildcards: get_sample_forward_cirri('{sample_id}'.format(sample_id=wildcards.sample) ), 
        rev=lambda wildcards: get_sample_reverse_cirri('{sample_id}'.format(sample_id=wildcards.sample) )    
    shell:  
        """ 
cat {params.fwd} > {output.R1} 
cat {params.rev} > {output.R2}         
"""

rule Trim_cirri:
    input:
        R1="results/cirri_raw/{sample}_1.fq.gz",
        R2="results/cirri_raw/{sample}_2.fq.gz"
    output:
        R1="results/cirri_trim/{sample}_1.fq.gz",
        R2="results/cirri_trim/{sample}_2.fq.gz"
    log:
        "results/logs/{sample}_fastp.log"
    threads:
        8
    shell:
        """
(fastp -i {input.R1} -I {input.R2} -o {output.R1} -O {output.R2} --length_required 100 --thread {threads} --low_complexity_fil$
 --json results/logs/fastp/{wildcards.sample}.fastp.json \
 --html results/logs/fastp/{wildcards.sample}.fastp.html ) &> {log}
        """


rule trinity_assembly_external:
    input:
         R1="results/cirri_raw/{sample}_1.fq.gz",
         R2="results/cirri_raw/{sample}_2.fq.gz"
    output:
        out="results/cirri_assembly/{sample}_trinity.Trinity.fas"
    params:
        outdir="results/cirri_assembly/{sample}_trinity",
        max_ram='500G'
    threads: 27
    envmodules:
        "anaconda3/2021.05",
        "trinity/2.13.2"
    log:
        "results/logs/cirri_assembly/{sample}_trinity.log"
    shell:
        "(printf 'starting Trinity assembly ...\n\n' ; Trinity --seqType fq --left {input.R1} --right {input.R2} "
        "--CPU {threads} --SS_lib_type FR --no_version_check --max_memory {params.max_ram} --output {params.outdir} --full_cleanup ; "
        "sleep 100 ; cp {params.outdir}.Trinity.fasta {output.out} ) &> {log} " 


rule trinity_longest_external:
    input:
        "results/cirri_assembly/{sample}_trinity.Trinity.fas"
    output:
        "results/cirri_assembly/{sample}_longest.fas"
    envmodules:
        "trinity/2.13.2"
    shell:
        """
$TRINITY_HOME/util/misc/get_longest_isoform_seq_per_trinity_gene.pl {input} > {output}
"""

rule add_Tax2headers_external:
    input:
        IN="results/cirri_assembly/{sample}_longest.fas"
    output:
        OUT="results/cirri_assembly_renamed/{sample}.fas"
    params:
        spec=lambda wildcards: get_taxon_cirri('{}'.format(wildcards.sample))
    shell:
        "cp {input.IN} {output.OUT} ; "
        "sed -i 's/ .*//g' {output.OUT} ; "
        "sed -i 's/>/>{params.spec}_/g' {output.OUT}"


#######################
## Funannotate Steps ##
#######################

### when using the official container, we dont need to run the setup step. It already contains the databases...

# with the new container all databases should be included...

rule funannotate_setup:
    output:
        touch("results/funannotate/setup.ok")
    params:
        databases="all",
        busco="all",
        DB=config["funannotate"]["DB"]
    container:
        config["funannotate"]["container"]
    #conda:
    #    "envs/funannotate_1.8.9.yaml"
    threads: 1
    log:
        "results/logs/funannotate_setup.log"
    shell:
        """
( funannotate setup --install {params.databases} --busco_db {params.busco} --database {params.DB} ) &> {log}
"""

# funannotate_1.8.9.yaml
rule funannotate_prep:
    input:
        Genome=config["genome"]
    output:
        clean="results/funannotate/genome.clean.fa",
        sort="results/funannotate/genome.clean.sorted.fa"
    params:
    threads: 1
    conda:
        "envs/funannotate_1.8.9.yaml"
    log:
        "results/logs/funannotate_clean_run.log"
    shell:
        """
( funannotate clean --input {input.Genome} --out {output.clean} --pident 95 --cov 95 --minlen 500
funannotate sort --input {output.clean} --out {output.sort} ) &> {log} 
"""

# databases are already present in the container

rule funannotate_train:
    input:
        Genome="results/funannotate/genome.clean.sorted.fa",
        R1=print_all_forward(),
        R2=print_all_reverse(),
        check="results/funannotate/setup.ok",
    output:
        "results/funannotate2/training/funannotate_train.pasa.gff3"
    params:
        spec=config["funannotate"]["spec"],
        max_intron=config["funannotate"]["intron"],
        out_dir="results/funannotate2",
    threads: 56
    container:
        config["funannotate"]["container"]
    log:
        "results/logs/funannotate2_train_run.log"
    shell:
        """
(funannotate train \
    --input {input.Genome} \
    --cpus {threads} \
    --species "{params.spec}" \
    --max_intronlen {params.max_intron} \
    --out {params.out_dir} \
    --left {input.R1} \
    --right {input.R2} ) &> {log}
"""


rule funannotate_predict2:
    input:
        Genome="results/funannotate/genome.clean.sorted.fa",
        check="results/funannotate/setup.ok",
        train="results/funannotate2/training/funannotate_train.pasa.gff3",
        orthoProt="results/orthofinder/merged_orthogroup_sequences.fa",
        TSA=get_all_tsa_files(),
        Cirri_assembled=expand("results/cirri_assembly_renamed/{cirri_sample}.fas", cirri_sample=CIRRI_SPEC)
    output:
        prot="results/funannotate2/predict_results/Sacculina_carcini.proteins.fa",
        annot="results/funannotate2/predict_results/Sacculina_carcini.gff3"
    params:
        spec=config["funannotate"]["spec"],
        max_intron=config["funannotate"]["intron"],
        out_dir="results/funannotate2",
    threads: 56
    container:
        config["funannotate"]["container"]
    log:
        "results/logs/funannotate2_predict_run.log"
    shell:
        """
(
#transfer augustus config if not present
[ ! -d "$(pwd)/results/funannotate2/config" ] && cp -r /usr/local/config $(pwd)/results/funannotate2/
export AUGUSTUS_CONFIG_PATH=$(pwd)/results/funannotate2/config

#transfer genemark key to HOME / CWD
[ ! -f $HOME/.gm_key ] && cp /opt/genemark/gm_key_64 .gm_key

funannotate predict --input {input.Genome} --transcript_evidence {input.TSA} {input.Cirri_assembled} --protein_evidence {input.orthoProt} --cpus {threads} --species "{params.spec}" --max_intronlen {params.max_intron} \
--out {params.out_dir} --optimize_augustus --organism other --busco_db arthropoda --busco_seed_species fly --name SACA --keep_evm \
) &> {log}
"""

rule funannotate_update:
    input:
        Genome="results/funannotate/genome.clean.sorted.fa",
        annot="results/funannotate2/predict_results/Sacculina_carcini.gff3",
        R1=print_all_forward(),
        R2=print_all_reverse(),
    output:
        xx="results/funannotate2/someupdate"
    params:
        spec=config["funannotate"]["spec"],
        max_intron=config["funannotate"]["intron"],
        out_dir="results/funannotate2",
    threads: 56
    container:
        config["funannotate"]["container"]
    log:
        "results/logs/funannotate_update_run.log"
    shell:
        """
(

funannotate update \
    --fasta {input.Genome} \
    --gff {input.annot} \
    --cpus {threads} \
    --species "{params.spec}" \
    --max_intronlen {params.max_intron} \
    --out {params.out_dir} \
    --left {input.R1} --right {input.R2} 

) &> {log}
"""

rule interproscan_funannotate:
    input:
        "results/funannotate2/predict_results/Sacculina_carcini.proteins.fa"
    output:
        "results/funannotate2/interproscan.output.xml"
    threads: 40
    envmodules:
        "interproscan/5.50-84.0"
    params:
        tmp="results/funannotate/inter_temp/",
        apps="CDD,COILS,Gene3D,HAMAP,MobiDBLite,PANTHER,Pfam,PIRSF,PRINTS,PROSITEPATTERNS,PROSITEPROFILES,SFLD,SMART,SUPERFAMILY,TIGRFAM"
    shell:
        """
interproscan.sh -input {input} -formats xml -disable-precalc --goterms --outfile {output} --seqtype p --tempdir {params.tmp} --verbose --cpu {threads} --applications {params.apps}
"""


rule funannotate_annotate:
    input:
        gff="results/funannotate2/predict_results/Sacculina_carcini.gff3",
        genome="results/funannotate2/predict_results/Sacculina_carcini.scaffolds.fa",
        iprscan="results/funannotate2/interproscan.output.xml"
    output:
        touch("results/funannotate2/annotate_step.complete")
    params:
        species=config["funannotate"]["spec"],
        predict_dir="results/funannotate2/predict_results",
        busco=config["funannotate"]["busco_db"],
        out_dir="results/funannotate2/annotated",
    threads: 40
    container:
        config["funannotate"]["container"]
    shell:
        """
funannotate annotate --input {params.predict_dir} --gff {input.gff} --fasta {input.genome} --iprscan {input.iprscan} --busco_db {params.busco} --out {params.out_dir} --cpus {threads}
        """

## not sure if it works like this ... might need to join conda and envmodules... 
# could also try to incorporate the singularity/docker container

### rule funannotate_annotate
# https://funannotate.readthedocs.io/en/latest/commands.html?highlight=bam#adding-functional-annotation 

###############
## ORTHOLOGY ##
###############

# orthofinder preparations need to be included here! to create the primary_transcripts directory....
# orthofinder analysis only with genome based gene predictions. 
# We dont include Translated Transcriptomes now!

rule run_orthofinder:
    output:
        dir=directory("results/orthofinder/run_1"),
        check=touch("results/orthofinder/run_1.ok"),
    threads:
        40
    params:
        input="resources/orthofinder/",
        base="results/orthofinder/run_1",
        postfix="my_output"
    log:
        "results/logs/orthofinder/run1.log"
    shell:
        """
( [ ! -d {output.dir} ] && mkdir -p results/orthofinder
orthofinder -M msa -t {threads} -f {params.input} -y -o {params.base} -n {params.postfix} ) &> {log} 
        """


rule merge_ortho_seqs:
    input:
        OrthoOK="results/orthofinder/run_1.ok",
    output:
        "results/orthofinder/merged_orthogroup_sequences.fa"
    threads: 1
    shell:
        """
cat results/orthofinder/run_1/Results_my_output/Orthogroup_Sequences/*.fa > {output}
        """


rule extend_orthofinder:
    input:
        OrthoOK="results/orthofinder/run_1.ok",
        Pep="results/funannotate2/predict_results/Sacculina_carcini.proteins.fa"
    output:
        dynamic("results/orthofinder/run_1/Results_my_output/WorkingDirectory/OrthoFinder/Results_my_output2/Orthogroup_Sequences/{orthogroup}.fa"),
    threads:
        40
    params:
        input="results/orthofinder/new_fasta_directory",
        wrkdr="results/orthofinder/run_1/Results_my_output/WorkingDirectory/",
        postfix="my_output2"
    shell:
        """
mkdir -p {params.input}/
cp {input.Pep} {params.input}/Sacculina_carcini.fas
orthofinder -M msa -t {threads} -b {params.wrkdr} -f {params.input} -y -n {params.postfix}
        """

rule rerun_orthofinder_root:
    input:
        dynamic("results/orthofinder/run_1/Results_my_output/WorkingDirectory/OrthoFinder/Results_my_output2/Orthogroup_Sequences/{orthogroup}.fa")
    output:
        touch("results/orthofinder/run_3.ok")
    threads: 40
    params:
        input="results/orthofinder/new_fasta_directory",
        wrkdr="results/orthofinder/run_1/Results_my_output/WorkingDirectory/",
        postfix="NewTree",
        outgroups="Notodromas_monacha,Darwinula_stevensoni"
    shell:
        """
echo {params.outgroups} | gotree reroot outgroup -i results/orthofinder/run_1/Results_my_output/WorkingDirectory/OrthoFinder/Results_my_output2/Species_Tree/SpeciesTree_rooted.txt -l - > \
results/orthofinder/SpeciesTree_rooted.nwk

orthofinder -M msa -t {threads} -ft results/orthofinder/run_1/Results_my_output/WorkingDirectory/OrthoFinder/Results_my_output2 -y -s results/orthofinder/SpeciesTree_rooted.nwk -n {params.postfix}
        """

#### need to take the input from the extend run!!!
rule interproscan_orthofinder:
    input:
        "results/orthofinder/run_1/Results_my_output/WorkingDirectory/OrthoFinder/Results_my_output2/Orthogroup_Sequences/{orthogroup}.fa"
    output:
        "results/orthofinder/interproscan/{orthogroup}.tsv"
    threads: 5
    envmodules:
        "interproscan/5.50-84.0"
    params:
        tmp="results/orthofinder/inter_temp/",
        apps="CDD,COILS,Gene3D,HAMAP,MobiDBLite,PANTHER,Pfam,PIRSF,PRINTS,PROSITEPATTERNS,PROSITEPROFILES,SFLD,SMART,SUPERFAMILY,TIGRFAM"

    shell:
        """
interproscan.sh -input {input} -formats tsv -disable-precalc --goterms --outfile {output} --seqtype p --tempdir {params.tmp} --verbose --cpu {threads} --applications {params.apps}
"""


########################
## RUN BUSCO ANALYSIS ##
########################


rule busco_genome:
    input:
        Genome="results/funannotate/genome.clean.sorted.fa"
    output:
        "results/busco_analysis/busco_genome/short_summary.specific.arthropoda_odb10.busco_genome.txt"
    params:
        dir="busco_genome",
        lineage="arthropoda_odb10",
        mode="genome",
        config="resources/busco_config.ini"
    threads: 20
    log:
        "results/logs/busco_analysis/busco_genome.log"
    shell:
        """
busco -f -m {params.mode} -i {input} -o {params.dir} -l {params.lineage} --cpu {threads} --config {params.config} &> {log}
        """


rule busco_fun_prot2:
    input:
        "results/funannotate2/predict_results/Sacculina_carcini.proteins.fa"
    output:
        "results/busco_analysis/busco_fun_prot2/short_summary.specific.arthropoda_odb10.busco_fun_prot2.txt"
    params:
        dir="busco_fun_prot2",
        lineage="arthropoda_odb10",
        mode="protein",
        config="resources/busco_config.ini"
    threads: workflow.cores
    log:
        "results/logs/busco_analysis/busco_fun_prot2.log"
    shell:
        """
( busco -f -m {params.mode} -i {input} -o {params.dir} -l {params.lineage} --cpu {threads} --config {params.config} ) &> {log}
        """


rule busco_summary:
    input:
        "results/busco_analysis/busco_genome/short_summary.specific.arthropoda_odb10.busco_genome.txt",
        "results/busco_analysis/busco_fun_prot2/short_summary.specific.arthropoda_odb10.busco_fun_prot2.txt",
    output:
        "results/busco_analysis/busco_summary/busco_figure.png"
    params:
        dir="results/busco_analysis/busco_summary"
    threads: 1
    shell:
        """
for file in {input}; do cp $file {params.dir}/ ; done
generate_plot.py -wd {params.dir}
        """


### Busco external TSA

rule busco_tsa:
    input: 
        get_tsa_file 
    output: 
        "results/busco_tsa/busco_{species}/short_summary.specific.arthropoda_odb10.busco_{species}.txt" 
    params:
        dir="busco_{species}",
        path="./results/busco_tsa/",
        lineage="arthropoda_odb10",
        mode="transcriptome",
        config="resources/busco_config.ini"
    threads: 20
    log:
        "results/logs/busco_tsa/busco_{species}.log"
    shell:
        """
busco -f -m {params.mode} -i {input} --out_path {params.path} -o {params.dir} -l {params.lineage} --cpu {threads} --config {params.config} &> {log}
        """


#### Busco cirripedia assembled

rule busco_cirri:
    input:
        "results/cirri_assembly_renamed/{cirri_sample}.fas"
    output:
        "results/busco_cirri/busco_{cirri_sample}/short_summary.specific.arthropoda_odb10.busco_{cirri_sample}.txt"
    params:
        dir="busco_{cirri_sample}",
        path="./results/busco_cirri/",
        lineage="arthropoda_odb10",
        mode="transcriptome",
        config="resources/busco_config.ini"
    threads: 20
    log:
        "results/logs/busco_cirri/busco_{cirri_sample}.log"
    shell:
        """
busco -f -m {params.mode} -i {input} --out_path {params.path} -o {params.dir} -l {params.lineage} --cpu {threads} --config {params.config} &> {log}
        """
